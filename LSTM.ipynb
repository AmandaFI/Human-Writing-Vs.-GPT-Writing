{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import pad_sequences\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data_pickles/train_test_val_Human_posTags', 'rb')\n",
    "X_human_train_posTags, X_human_test_posTags, X_human_val_posTags = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "Y_human_train = np.zeros(len(X_human_train_posTags))\n",
    "Y_human_test = np.zeros(len(X_human_test_posTags))\n",
    "Y_human_val = np.zeros(len(X_human_val_posTags))\n",
    "\n",
    "\n",
    "file = open('data_pickles/train_test_val_GPT_posTags', 'rb')\n",
    "X_gpt_train_posTags, X_gpt_test_posTags, X_gpt_val_posTags = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "Y_gpt_train = np.ones(len(X_gpt_train_posTags))\n",
    "Y_gpt_test = np.ones(len(X_gpt_test_posTags))\n",
    "Y_gpt_val = np.ones(len(X_gpt_val_posTags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 435, 95, 95, 93, 93)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_human_train_posTags), len(Y_human_train), len(X_human_test_posTags), len(Y_human_test), len(X_human_val_posTags), len(Y_human_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_human_train_posTags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((X_human_train_posTags, X_gpt_train_posTags))\n",
    "Y_train = np.hstack((Y_human_train, Y_gpt_train))\n",
    "\n",
    "X_test = np.hstack((X_human_test_posTags, X_gpt_test_posTags))\n",
    "Y_test = np.hstack((Y_human_test, Y_gpt_test))\n",
    "\n",
    "# Juntando train e test\n",
    "# # ------------------------------------------------------\n",
    "# X_train = np.hstack((X_train, X_test))\n",
    "# Y_train = np.hstack((Y_train, Y_test))\n",
    "# # ------------------------------------------------------\n",
    "\n",
    "\n",
    "X_val = np.hstack((X_human_val_posTags, X_gpt_val_posTags))\n",
    "Y_val = np.hstack((Y_human_val, Y_gpt_val))\n",
    "\n",
    "full_dataset = np.hstack((X_train, X_test, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [' '.join(data) for data in X_train]\n",
    "X_test = [' '.join(data) for data in X_test]\n",
    "X_val = [' '.join(data) for data in X_val]\n",
    "\n",
    "full_dataset = [' '.join(data) for data in full_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2022/01/sentiment-analysis-with-lstm/\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n",
    "# https://keras.io/api/layers/core_layers/embedding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 226 = tipos de postags possiveis, talvez trocar para somente as que aparecem nos arquivos\n",
    "# vocab_size = 226 # choose based on statistics\n",
    "\n",
    "# 93%\n",
    "# vocab_size = 50\n",
    "# oov_tok = ''\n",
    "# embedding_dim = 200\n",
    "# max_length = 200\n",
    "\n",
    "vocab_size = 55\n",
    "oov_tok = ''\n",
    "embedding_dim = 150\n",
    "max_length = 200\n",
    "\n",
    "\n",
    "\n",
    "# max_length = 500\n",
    "\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "\n",
    "# tokenizer.fit_on_texts(X_train)\n",
    "tokenizer.fit_on_texts(full_dataset)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "val_padded = pad_sequences(val_sequences, padding='post', maxlen=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded, Y_train = shuffle(train_padded, Y_train)\n",
    "test_padded, Y_test = shuffle(test_padded, Y_test)\n",
    "val_padded, Y_val = shuffle(val_padded, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dataset_test= [test_padded, Y_test]\n",
    "\n",
    "filename = 'lstm_dataset_test'\n",
    "file = open(filename, 'wb')\n",
    "pickle.dump(lstm_dataset_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 16,  4,  2,  3,  9,  7,  2, 14,  7,  3,  6,  2,  5, 23, 10, 10,\n",
       "        3,  7,  3,  5,  3,  5,  4,  2, 16,  5,  3,  9, 16,  2, 16,  4,  2,\n",
       "       10,  3,  5, 13,  8,  4,  2,  9, 10, 16,  3,  7, 16, 10, 15,  6, 13,\n",
       "        2,  4,  6,  7,  5, 21,  6,  2, 16,  3, 29, 19,  8,  4,  6,  2, 23,\n",
       "       10, 11,  4,  2, 12, 15,  2,  3,  7, 26, 17,  9,  6,  2, 19,  8, 15,\n",
       "        3,  4,  2,  4,  2, 16, 13,  8,  4,  5, 12,  2, 13,  8,  7,  4,  2,\n",
       "       21,  2,  2, 12,  8,  3,  6,  7,  6,  3,  7, 11,  7, 19,  8, 15, 13,\n",
       "        8, 14,  4,  2, 11,  3,  2, 12, 10, 15,  3, 10,  6,  2, 12, 15, 15,\n",
       "        4,  2, 10, 12, 10,  4,  2,  3,  5, 16,  9,  6,  5, 13,  4,  2,  3,\n",
       "        2,  7, 11,  7,  5, 11,  5,  4,  6,  2,  3,  5, 17, 15, 14,  3,  2,\n",
       "        3,  4, 14,  2,  3,  6,  2,  7, 11,  4,  2,  3,  6,  2,  7, 11,  7,\n",
       "       12,  6, 15,  7,  3,  4, 19,  8,  6, 11, 17, 15,  7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((870, 200), (186, 200))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded.shape, val_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = 50\n",
    "# oov_tok = ''\n",
    "\n",
    "# tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "# tokenizer.fit_on_texts(X_train)\n",
    "# word_index = tokenizer.word_index\n",
    "\n",
    "# embedding_dim = 100\n",
    "# padding_type='post'\n",
    "\n",
    "\n",
    "# train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "# train_padded = pad_sequences(train_sequences, padding='post')\n",
    "\n",
    "# test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "# test_padded = pad_sequences(test_sequences, padding='post')\n",
    "\n",
    "# val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "# val_padded = pad_sequences(val_sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 150)          8250      \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              110080    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,491\n",
      "Trainable params: 122,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = keras.Sequential([\n",
    "#     keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "#     keras.layers.Bidirectional(keras.layers.LSTM(128)),\n",
    "#     keras.layers.Dense(32, activation='relu'),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# 93%\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "#     keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "#     # keras.layers.Dense(64, activation='relu'),\n",
    "\n",
    "#     keras.layers.Dense(32, activation='relu'),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# ESSE\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "#     keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "#     # keras.layers.Dense(32, activation='relu'),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "#     keras.layers.Dense(32, activation='relu'),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "#     keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "#     keras.layers.Dense(24, activation='relu'),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# 9402_9086_9157\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "#     # keras.layers.SpatialDropout1D(0.2),\n",
    "#     keras.layers.Bidirectional(keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2)),\n",
    "#     # keras.layers.Dense(32, activation='relu'),\n",
    "#     # keras.layers.Dropout(0.2),\n",
    "#     keras.layers.Dense(32, activation='relu'),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = EarlyStopping(monitor='accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "28/28 [==============================] - 32s 927ms/step - loss: 0.6285 - accuracy: 0.6851 - val_loss: 0.5491 - val_accuracy: 0.7151\n",
      "Epoch 2/27\n",
      "28/28 [==============================] - 24s 857ms/step - loss: 0.3750 - accuracy: 0.8563 - val_loss: 0.3151 - val_accuracy: 0.8656\n",
      "Epoch 3/27\n",
      "28/28 [==============================] - 25s 892ms/step - loss: 0.2477 - accuracy: 0.9103 - val_loss: 0.3337 - val_accuracy: 0.8925\n",
      "Epoch 4/27\n",
      "28/28 [==============================] - 23s 812ms/step - loss: 0.2340 - accuracy: 0.9115 - val_loss: 0.2417 - val_accuracy: 0.8978\n",
      "Epoch 5/27\n",
      "28/28 [==============================] - 23s 818ms/step - loss: 0.2438 - accuracy: 0.9092 - val_loss: 0.3282 - val_accuracy: 0.8817\n",
      "Epoch 6/27\n",
      "28/28 [==============================] - 23s 811ms/step - loss: 0.2181 - accuracy: 0.9207 - val_loss: 0.3895 - val_accuracy: 0.8710\n",
      "Epoch 7/27\n",
      "28/28 [==============================] - 23s 818ms/step - loss: 0.2563 - accuracy: 0.9092 - val_loss: 0.4329 - val_accuracy: 0.8548\n",
      "Epoch 8/27\n",
      "28/28 [==============================] - 23s 817ms/step - loss: 0.2351 - accuracy: 0.9161 - val_loss: 0.2376 - val_accuracy: 0.8925\n",
      "Epoch 9/27\n",
      "28/28 [==============================] - 24s 843ms/step - loss: 0.1868 - accuracy: 0.9356 - val_loss: 0.2575 - val_accuracy: 0.9032\n",
      "Epoch 10/27\n",
      "28/28 [==============================] - 23s 825ms/step - loss: 0.1782 - accuracy: 0.9299 - val_loss: 0.2196 - val_accuracy: 0.9032\n",
      "Epoch 11/27\n",
      "28/28 [==============================] - 23s 822ms/step - loss: 0.1927 - accuracy: 0.9322 - val_loss: 0.2229 - val_accuracy: 0.9086\n",
      "Epoch 12/27\n",
      "28/28 [==============================] - 24s 853ms/step - loss: 0.1643 - accuracy: 0.9368 - val_loss: 0.3230 - val_accuracy: 0.8871\n",
      "Epoch 13/27\n",
      "28/28 [==============================] - 23s 820ms/step - loss: 0.1710 - accuracy: 0.9310 - val_loss: 0.2042 - val_accuracy: 0.9032\n",
      "Epoch 14/27\n",
      "28/28 [==============================] - 23s 819ms/step - loss: 0.1592 - accuracy: 0.9391 - val_loss: 0.2537 - val_accuracy: 0.9032\n",
      "Epoch 15/27\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 0.1524 - accuracy: 0.9391 - val_loss: 0.2238 - val_accuracy: 0.9140\n",
      "Epoch 16/27\n",
      "28/28 [==============================] - 23s 820ms/step - loss: 0.1936 - accuracy: 0.9322 - val_loss: 0.2134 - val_accuracy: 0.9301\n",
      "Epoch 17/27\n",
      "28/28 [==============================] - 23s 819ms/step - loss: 0.2082 - accuracy: 0.9230 - val_loss: 0.2193 - val_accuracy: 0.9032\n",
      "Epoch 18/27\n",
      "28/28 [==============================] - 23s 826ms/step - loss: 0.1537 - accuracy: 0.9448 - val_loss: 0.3424 - val_accuracy: 0.8871\n",
      "Epoch 19/27\n",
      "28/28 [==============================] - 24s 845ms/step - loss: 0.1778 - accuracy: 0.9368 - val_loss: 0.2283 - val_accuracy: 0.9194\n",
      "Epoch 20/27\n",
      "28/28 [==============================] - 23s 830ms/step - loss: 0.1660 - accuracy: 0.9287 - val_loss: 0.2169 - val_accuracy: 0.9086\n",
      "Epoch 21/27\n",
      "28/28 [==============================] - 23s 833ms/step - loss: 0.1721 - accuracy: 0.9299 - val_loss: 0.2409 - val_accuracy: 0.9032\n",
      "Epoch 22/27\n",
      "28/28 [==============================] - 23s 820ms/step - loss: 0.1441 - accuracy: 0.9460 - val_loss: 0.2277 - val_accuracy: 0.9032\n",
      "Epoch 23/27\n",
      "28/28 [==============================] - 23s 831ms/step - loss: 0.1264 - accuracy: 0.9506 - val_loss: 0.2113 - val_accuracy: 0.9194\n",
      "Epoch 24/27\n",
      "28/28 [==============================] - 23s 823ms/step - loss: 0.1152 - accuracy: 0.9552 - val_loss: 0.2240 - val_accuracy: 0.9194\n",
      "Epoch 25/27\n",
      "28/28 [==============================] - 23s 820ms/step - loss: 0.1458 - accuracy: 0.9506 - val_loss: 0.2544 - val_accuracy: 0.9032\n",
      "Epoch 26/27\n",
      "28/28 [==============================] - 23s 827ms/step - loss: 0.1661 - accuracy: 0.9310 - val_loss: 0.2246 - val_accuracy: 0.9086\n",
      "Epoch 27/27\n",
      "28/28 [==============================] - 23s 817ms/step - loss: 0.1459 - accuracy: 0.9437 - val_loss: 0.2562 - val_accuracy: 0.9140\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 27\n",
    "history = model.fit(train_padded, Y_train, \n",
    "                    epochs=num_epochs, \n",
    "                    verbose=1, \n",
    "                    shuffle=True,\n",
    "                    validation_data=(val_padded, Y_val),\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelo_9437_9140_9157.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "24/24 [==============================] - 93s 4s/step - loss: 0.6468 - accuracy: 0.6114 - val_loss: 0.5354 - val_accuracy: 0.7979\n",
      "Epoch 2/25\n",
      "24/24 [==============================] - 78s 3s/step - loss: 0.5141 - accuracy: 0.7586 - val_loss: 0.3648 - val_accuracy: 0.8564\n",
      "Epoch 3/25\n",
      "24/24 [==============================] - 64s 3s/step - loss: 0.3412 - accuracy: 0.8554 - val_loss: 0.2650 - val_accuracy: 0.9043\n",
      "Epoch 4/25\n",
      "24/24 [==============================] - 63s 3s/step - loss: 0.3493 - accuracy: 0.8475 - val_loss: 0.3702 - val_accuracy: 0.8404\n",
      "Epoch 5/25\n",
      "24/24 [==============================] - 54s 2s/step - loss: 0.2925 - accuracy: 0.8780 - val_loss: 0.2175 - val_accuracy: 0.9202\n",
      "Epoch 6/25\n",
      "24/24 [==============================] - 52s 2s/step - loss: 0.2331 - accuracy: 0.9072 - val_loss: 0.2396 - val_accuracy: 0.8777\n",
      "Epoch 7/25\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.2661 - accuracy: 0.8873 - val_loss: 0.2612 - val_accuracy: 0.8883\n",
      "Epoch 8/25\n",
      "24/24 [==============================] - 56s 2s/step - loss: 0.2235 - accuracy: 0.9085 - val_loss: 0.1951 - val_accuracy: 0.9362\n",
      "Epoch 9/25\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.2284 - accuracy: 0.9072 - val_loss: 0.2192 - val_accuracy: 0.9096\n",
      "Epoch 10/25\n",
      "24/24 [==============================] - 67s 3s/step - loss: 0.2442 - accuracy: 0.9045 - val_loss: 0.1966 - val_accuracy: 0.9255\n",
      "Epoch 11/25\n",
      "24/24 [==============================] - 58s 2s/step - loss: 0.1790 - accuracy: 0.9218 - val_loss: 0.1937 - val_accuracy: 0.9096\n",
      "Epoch 12/25\n",
      "24/24 [==============================] - 54s 2s/step - loss: 0.1673 - accuracy: 0.9390 - val_loss: 0.2114 - val_accuracy: 0.9255\n",
      "Epoch 13/25\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.1776 - accuracy: 0.9324 - val_loss: 0.1970 - val_accuracy: 0.9149\n",
      "Epoch 14/25\n",
      "24/24 [==============================] - 56s 2s/step - loss: 0.1435 - accuracy: 0.9443 - val_loss: 0.1925 - val_accuracy: 0.9202\n",
      "Epoch 15/25\n",
      "24/24 [==============================] - 52s 2s/step - loss: 0.1674 - accuracy: 0.9337 - val_loss: 0.2112 - val_accuracy: 0.9149\n",
      "Epoch 16/25\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.1410 - accuracy: 0.9390 - val_loss: 0.1803 - val_accuracy: 0.9468\n",
      "Epoch 17/25\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.1387 - accuracy: 0.9390 - val_loss: 0.1901 - val_accuracy: 0.9202\n",
      "Epoch 18/25\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.1469 - accuracy: 0.9363 - val_loss: 0.2468 - val_accuracy: 0.8989\n",
      "Epoch 19/25\n",
      "24/24 [==============================] - 55s 2s/step - loss: 0.1317 - accuracy: 0.9469 - val_loss: 0.2434 - val_accuracy: 0.9043\n",
      "Epoch 20/25\n",
      "24/24 [==============================] - 52s 2s/step - loss: 0.1054 - accuracy: 0.9536 - val_loss: 0.2703 - val_accuracy: 0.9043\n",
      "Epoch 21/25\n",
      "24/24 [==============================] - 54s 2s/step - loss: 0.1228 - accuracy: 0.9456 - val_loss: 0.3076 - val_accuracy: 0.8883\n",
      "Epoch 22/25\n",
      "24/24 [==============================] - 71s 3s/step - loss: 0.1154 - accuracy: 0.9589 - val_loss: 0.2595 - val_accuracy: 0.9043\n",
      "Epoch 23/25\n",
      "24/24 [==============================] - 64s 3s/step - loss: 0.1171 - accuracy: 0.9430 - val_loss: 0.2580 - val_accuracy: 0.9096\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "history = model.fit(train_padded, Y_train, \n",
    "                    epochs=num_epochs, \n",
    "                    verbose=1, \n",
    "                    #validation_split=0.1,\n",
    "                    validation_data=(val_padded, Y_val),\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 0.3139588236808777\n",
      "Evaluation accuracy: 0.9157894849777222\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_padded, Y_test, verbose=0)\n",
    "print('Evaluation loss:', score[0])\n",
    "print('Evaluation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
