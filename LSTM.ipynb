{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data_pickles/train_test_val_Human_posTags', 'rb')\n",
    "X_human_train_posTags, X_human_test_posTags, X_human_val_posTags = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "Y_human_train = np.zeros(len(X_human_train_posTags))\n",
    "Y_human_test = np.zeros(len(X_human_test_posTags))\n",
    "Y_human_val = np.zeros(len(X_human_val_posTags))\n",
    "\n",
    "\n",
    "file = open('data_pickles/train_test_val_GPT_posTags', 'rb')\n",
    "X_gpt_train_posTags, X_gpt_test_posTags, X_gpt_val_posTags = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "Y_gpt_train = np.ones(len(X_gpt_train_posTags))\n",
    "Y_gpt_test = np.ones(len(X_gpt_test_posTags))\n",
    "Y_gpt_val = np.ones(len(X_gpt_val_posTags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 435, 95, 95, 93, 93)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_human_train_posTags), len(Y_human_train), len(X_human_test_posTags), len(Y_human_test), len(X_human_val_posTags), len(Y_human_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((X_human_train_posTags, X_gpt_train_posTags))\n",
    "Y_train = np.hstack((Y_human_train, Y_gpt_train))\n",
    "\n",
    "X_test = np.hstack((X_human_test_posTags, X_gpt_test_posTags))\n",
    "Y_test = np.hstack((Y_human_test, Y_gpt_test))\n",
    "\n",
    "X_val = np.hstack((X_human_val_posTags, X_gpt_val_posTags))\n",
    "Y_val = np.hstack((Y_human_val, Y_gpt_val))\n",
    "\n",
    "full_dataset = np.hstack((X_train, X_test, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [' '.join(data) for data in X_train]\n",
    "X_test = [' '.join(data) for data in X_test]\n",
    "X_val = [' '.join(data) for data in X_val]\n",
    "\n",
    "full_dataset = [' '.join(data) for data in full_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 55\n",
    "oov_tok = ''\n",
    "embedding_dim = 150\n",
    "max_length = 200\n",
    "\n",
    "padding_type='post'\n",
    "trunc_type='post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "\n",
    "tokenizer.fit_on_texts(full_dataset)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "val_padded = pad_sequences(val_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded, Y_train = shuffle(train_padded, Y_train)\n",
    "test_padded, Y_test = shuffle(test_padded, Y_test)\n",
    "val_padded, Y_val = shuffle(val_padded, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dataset_test= [test_padded, Y_test]\n",
    "\n",
    "filename = 'lstm_dataset_test'\n",
    "file = open(filename, 'wb')\n",
    "pickle.dump(lstm_dataset_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((870, 200), (186, 200))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded.shape, val_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 150)          8250      \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              110080    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,491\n",
      "Trainable params: 122,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = EarlyStopping(monitor='accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 27\n",
    "history = model.fit(train_padded, Y_train, \n",
    "                    epochs=num_epochs, \n",
    "                    verbose=1, \n",
    "                    shuffle=True,\n",
    "                    validation_data=(val_padded, Y_val),\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelo_9437_9140_9157.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation loss: 0.3139588236808777\n",
      "Evaluation accuracy: 0.9157894849777222\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_padded, Y_test, verbose=0)\n",
    "print('Evaluation loss:', score[0])\n",
    "print('Evaluation accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
